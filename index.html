<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Assistant - Realtime API</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Orbitron:wght@400;500;700;900&family=Exo+2:wght@300;400;500;600;700&display=swap');
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Exo 2', sans-serif;
            overflow: hidden;
            background: radial-gradient(ellipse at center, #1a1a2e 0%, #16213e 30%, #0f3460 60%, #0c0c0c 100%);
            position: relative;
            width: 100vw;
            height: 100vh;
        }
        
        /* Animated background particles */
        .bg-particles {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            overflow: hidden;
            z-index: 1;
        }
        
        .particle {
            position: absolute;
            background: radial-gradient(circle, rgba(0, 255, 255, 0.6), rgba(255, 0, 255, 0.3), transparent 70%);
            border-radius: 50%;
            animation: float 8s infinite ease-in-out;
            filter: blur(1px);
        }
        
        .particle:nth-child(1) { width: 4px; height: 4px; top: 20%; left: 10%; animation-delay: 0s; }
        .particle:nth-child(2) { width: 6px; height: 6px; top: 80%; left: 20%; animation-delay: 1s; }
        .particle:nth-child(3) { width: 3px; height: 3px; top: 40%; left: 80%; animation-delay: 2s; }
        .particle:nth-child(4) { width: 5px; height: 5px; top: 60%; left: 90%; animation-delay: 3s; }
        .particle:nth-child(5) { width: 4px; height: 4px; top: 10%; left: 60%; animation-delay: 4s; }
        .particle:nth-child(6) { width: 7px; height: 7px; top: 90%; left: 70%; animation-delay: 5s; }
        
        @keyframes float {
            0%, 100% { 
                transform: translateY(0px) translateX(0px) rotate(0deg) scale(1); 
                opacity: 0.8; 
            }
            25% { 
                transform: translateY(-25px) translateX(10px) rotate(90deg) scale(1.2); 
                opacity: 0.6; 
            }
            50% { 
                transform: translateY(-15px) translateX(-5px) rotate(180deg) scale(0.8); 
                opacity: 0.4; 
            }
            75% { 
                transform: translateY(-35px) translateX(15px) rotate(270deg) scale(1.1); 
                opacity: 0.7; 
            }
        }
        
        /* Enhanced Futuristic Orb */
        .orb-container {
            position: relative;
            z-index: 10;
        }
        
        .orb {
            width: 320px;
            height: 320px;
            border-radius: 50%;
            position: relative;
            background: 
                radial-gradient(ellipse at 25% 25%, rgba(0, 255, 255, 0.4) 0%, transparent 50%),
                radial-gradient(ellipse at 75% 75%, rgba(255, 0, 255, 0.3) 0%, transparent 50%),
                radial-gradient(circle at center, #1a1a2e 0%, #16213e 40%, #0f3460 80%, #533a7b 100%);
            box-shadow: 
                0 0 40px rgba(0, 255, 255, 0.4),
                0 0 70px rgba(255, 0, 255, 0.3),
                0 0 100px rgba(139, 92, 246, 0.2),
                inset 0 0 60px rgba(255, 255, 255, 0.05),
                inset 0 0 20px rgba(0, 255, 255, 0.1);
            transition: all 1.2s cubic-bezier(0.25, 0.46, 0.45, 0.94);
            border: 1px solid rgba(0, 255, 255, 0.2);
            backdrop-filter: blur(10px);
            cursor: pointer;
        }
        
        .orb::before {
            content: '';
            position: absolute;
            top: -8px;
            left: -8px;
            right: -8px;
            bottom: -8px;
            border-radius: 50%;
            background: conic-gradient(
                from 0deg, 
                transparent 0%, 
                rgba(0, 255, 255, 0.2) 25%, 
                transparent 50%, 
                rgba(255, 0, 255, 0.2) 75%, 
                transparent 100%
            );
            animation: orbRotate 12s linear infinite;
            z-index: -1;
            filter: blur(2px);
        }
        
        @keyframes orbRotate {
            from { transform: rotate(0deg); }
            to { transform: rotate(360deg); }
        }

        /* IDLE state */
        @keyframes idleBreath {
            0%, 100% { 
                transform: scale(1) rotate(0deg);
                box-shadow: 
                    0 0 40px rgba(0, 255, 255, 0.4),
                    0 0 70px rgba(255, 0, 255, 0.3),
                    0 0 100px rgba(139, 92, 246, 0.2);
            }
            50% { 
                transform: scale(1.03) rotate(1deg);
                box-shadow: 
                    0 0 50px rgba(0, 255, 255, 0.5),
                    0 0 80px rgba(255, 0, 255, 0.4),
                    0 0 110px rgba(139, 92, 246, 0.3);
            }
        }
        .orb.idle {
            animation: idleBreath 8s infinite ease-in-out;
        }
        
        /* LISTENING state */
        @keyframes listeningPulse {
            0%, 100% { 
                transform: scale(1.08) rotate(-1deg);
                box-shadow: 
                    0 0 60px rgba(0, 255, 255, 0.7),
                    0 0 90px rgba(255, 0, 255, 0.5),
                    0 0 120px rgba(139, 92, 246, 0.4);
            }
            50% { 
                transform: scale(1.15) rotate(1deg);
                box-shadow: 
                    0 0 80px rgba(0, 255, 255, 0.9),
                    0 0 110px rgba(255, 0, 255, 0.7),
                    0 0 140px rgba(139, 92, 246, 0.5);
            }
        }
        .orb.listening {
            animation: listeningPulse 1.5s infinite ease-in-out;
            background: 
                radial-gradient(ellipse at 25% 25%, rgba(0, 255, 255, 0.6) 0%, transparent 50%),
                radial-gradient(ellipse at 75% 75%, rgba(255, 0, 255, 0.4) 0%, transparent 50%),
                radial-gradient(circle at center, #1a1a2e 0%, #16213e 30%, #0f3460 70%, #3b82f6 100%);
        }

        /* THINKING state */
        @keyframes thinkingPulse {
            0%, 100% { transform: scale(1.02) rotate(-0.5deg); }
            50% { transform: scale(1.06) rotate(0.5deg); }
        }
        .orb.thinking {
            background: 
                radial-gradient(ellipse at 35% 35%, rgba(255, 0, 255, 0.4) 0%, transparent 50%),
                radial-gradient(ellipse at 65% 65%, rgba(0, 255, 255, 0.3) 0%, transparent 50%),
                radial-gradient(circle at center, #1a1a2e 0%, #16213e 30%, #533a7b 70%, #8b5cf6 100%);
            animation: thinkingPulse 2s ease-in-out infinite;
        }

        /* SPEAKING state */
        @keyframes speakingWaves {
            0%, 100% { 
                transform: scale(1.04) rotate(-1deg);
                box-shadow: 
                    0 0 50px rgba(255, 255, 0, 0.6),
                    0 0 80px rgba(255, 0, 255, 0.4),
                    0 0 110px rgba(0, 255, 255, 0.3);
            }
            50% { 
                transform: scale(1.12) rotate(1deg);
                box-shadow: 
                    0 0 80px rgba(255, 255, 0, 0.9),
                    0 0 110px rgba(255, 0, 255, 0.7),
                    0 0 140px rgba(0, 255, 255, 0.5);
            }
        }
        .orb.speaking {
            animation: speakingWaves 1.2s infinite ease-in-out;
            background: 
                radial-gradient(ellipse at 30% 30%, rgba(255, 255, 0, 0.5) 0%, transparent 50%),
                radial-gradient(ellipse at 70% 70%, rgba(255, 0, 255, 0.3) 0%, transparent 50%),
                radial-gradient(circle at center, #1a1a2e 0%, #16213e 20%, #ffaa00 60%, #8b5cf6 100%);
        }
        
        /* Status text */
        .status-text {
            position: absolute;
            bottom: -80px;
            width: 100%;
            text-align: center;
            font-family: 'Orbitron', monospace;
            font-size: 1.2rem;
            font-weight: 400;
            color: transparent;
            background: linear-gradient(
                135deg, 
                rgba(0, 255, 255, 0.8) 0%, 
                rgba(255, 0, 255, 0.6) 50%, 
                rgba(255, 255, 0, 0.4) 100%
            );
            background-clip: text;
            -webkit-background-clip: text;
            text-shadow: 
                0 0 15px rgba(0, 255, 255, 0.3),
                0 2px 10px rgba(255, 0, 255, 0.2);
            transition: all 0.6s cubic-bezier(0.25, 0.46, 0.45, 0.94);
            letter-spacing: 1.5px;
            animation: textGlow 3s ease-in-out infinite;
        }
        
        @keyframes textGlow {
            0%, 100% { 
                opacity: 0.8;
                transform: translateY(0px);
            }
            50% { 
                opacity: 1;
                transform: translateY(-2px);
            }
        }

        /* Touch indicator */
        .touch-indicator {
            position: absolute;
            top: 20px;
            right: 20px;
            font-family: 'Orbitron', monospace;
            font-size: 0.9rem;
            color: rgba(0, 255, 255, 0.7);
            z-index: 20;
            text-shadow: 0 0 10px rgba(0, 255, 255, 0.5);
        }

        /* Mode indicator */
        .mode-indicator {
            position: absolute;
            bottom: 20px;
            left: 20px;
            font-family: 'Orbitron', monospace;
            font-size: 0.8rem;
            color: rgba(0, 255, 255, 0.6);
            z-index: 20;
            text-shadow: 0 0 8px rgba(0, 255, 255, 0.4);
            opacity: 0;
            transition: opacity 0.5s ease-in-out;
        }
        
        .mode-indicator.visible {
            opacity: 1;
        }
        
        @keyframes pulseHint {
            0%, 100% { opacity: 0.7; }
            50% { opacity: 1; }
        }
        
        .pulse-hint {
            animation: pulseHint 2s infinite ease-in-out;
        }
    </style>
</head>
<body>
    <!-- Animated Background -->
    <div class="bg-particles">
        <div class="particle"></div>
        <div class="particle"></div>
        <div class="particle"></div>
        <div class="particle"></div>
        <div class="particle"></div>
        <div class="particle"></div>
    </div>
    
    <!-- Touch Indicator -->
    <div class="touch-indicator pulse-hint">
        TAP TO ACTIVATE
    </div>
    
    <!-- System Mode Indicator -->
    <div class="mode-indicator" id="mode-indicator">
        REALTIME API MODE
    </div>
    
    <!-- Codespace Configuration (only shown when needed) -->
    <div id="codespace-config" style="display: none; position: fixed; top: 50%; left: 50%; transform: translate(-50%, -50%); background: rgba(0,0,0,0.9); padding: 20px; border-radius: 10px; border: 1px solid #0ff; color: #0ff; font-family: 'Orbitron', monospace; z-index: 1000;">
        <h3 style="margin-top: 0;">🔧 Codespace Configuration</h3>
        <p>Enter your Codespace server URL:</p>
        <input type="text" id="codespace-input" placeholder="https://your-name-3001.app.github.dev" 
               style="width: 100%; padding: 8px; background: #1a1a2e; border: 1px solid #0ff; color: #0ff; border-radius: 4px;">
        <div style="margin-top: 10px;">
            <button onclick="saveCodespaceUrl()" style="background: #0ff; color: #000; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer; margin-right: 10px;">Save</button>
            <button onclick="hideCodespaceConfig()" style="background: #333; color: #0ff; border: 1px solid #0ff; padding: 8px 16px; border-radius: 4px; cursor: pointer;">Cancel</button>
        </div>
        <p style="font-size: 12px; margin-bottom: 0;">💡 Find this URL in your Codespace browser tab</p>
    </div>
    
    <!-- Main Assistant Interface -->
    <div class="relative flex items-center justify-center w-full h-full">
        <div class="orb-container">
            <div id="persona-orb" class="orb idle"></div>
            <div id="status-text" class="status-text">TAP TO START</div>
        </div>
    </div>

    <script>
        /*
         * AI Voice Assistant - OpenAI Realtime API Implementation
         * 
         * Pure Realtime API implementation with server-side proxy for authentication.
         * No backup systems - uses only OpenAI's real-time voice-to-voice API.
         */

        const personaOrb = document.getElementById('persona-orb');
        const statusText = document.getElementById('status-text');
        const touchIndicator = document.querySelector('.touch-indicator');
        const modeIndicator = document.getElementById('mode-indicator');

        // Codespace URL auto-detection
        function detectCodespaceURL() {
            // Try multiple detection methods
            const methods = [
                // Method 1: Check URL parameters
                () => {
                    const params = new URLSearchParams(window.location.search);
                    const codespace = params.get('codespace') || params.get('server');
                    if (codespace && codespace.includes('app.github.dev')) {
                        return `wss://${codespace}/realtime`;
                    }
                    return null;
                },
                
                // Method 2: Check localStorage for saved codespace
                () => {
                    try {
                        const saved = localStorage.getItem('codespace_url');
                        if (saved && saved.includes('app.github.dev')) {
                            return saved;
                        }
                    } catch (e) {}
                    return null;
                },
                
                // Method 3: Check document referrer
                () => {
                    if (document.referrer && document.referrer.includes('app.github.dev')) {
                        const match = document.referrer.match(/https:\/\/([^\/]+)/);
                        if (match) {
                            const domain = match[1].replace(/-\d+\.app\.github\.dev/, '-3001.app.github.dev');
                            return `wss://${domain}/realtime`;
                        }
                    }
                    return null;
                },
                
                // Method 4: Check for saved user-provided URL
                () => {
                    const saved = localStorage.getItem('user_provided_codespace');
                    if (saved) return saved;
                    return null;
                },
                
                // Method 5: Show config UI (as final fallback)
                () => {
                    showCodespaceConfig();
                    return null; // Will be handled by the UI
                }
            ];
            
            // Try each method until one works
            for (const method of methods) {
                try {
                    const result = method();
                    if (result) {
                        console.log('🔧 Codespace URL detected via method:', method.name || 'anonymous');
                        return result;
                    }
                } catch (e) {
                    console.warn('⚠️ Detection method failed:', e);
                }
            }
            
            return null;
        }

        // Realtime API Configuration - Auto-detect environment
        const getProxyURL = () => {
            const hostname = window.location.hostname;
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            
            // Production deployments
            if (hostname === 'shucho.space') {
                // Use Railway deployment (supports WebSockets natively)
                const railwayUrl = 'wss://openai-realtime-proxy-production-710a.up.railway.app/realtime';
                
                console.log('🔧 Using Railway deployment (WebSocket compatible)');
                return railwayUrl;
                
                // Fallback: Try codespace detection if Vercel fails
                // const codespaceUrl = detectCodespaceURL();
                // if (codespaceUrl) {
                //     console.log('🔧 Fallback to codespace:', codespaceUrl);
                //     return codespaceUrl;
                // }
            }
            
            // GitHub Pages
            if (hostname.includes('github.io')) {
                const codespaceUrl = detectCodespaceURL();
                if (codespaceUrl) return codespaceUrl;
                
                // Fallback to detection
                return 'wss://your-codespace-3001.app.github.dev/realtime';
            }
            
            // GitHub Codespaces (pattern: *.app.github.dev)
            if (hostname.includes('app.github.dev')) {
                // Use current codespace but port 3001
                return `wss://${hostname.replace(/(-\d+)?\.app\.github\.dev/, '-3001.app.github.dev')}/realtime`;
            }
            
            // Vercel deployments
            if (hostname.includes('vercel.app')) {
                return `${protocol}//${hostname}/realtime`;
            }
            
            // Railway deployments
            if (hostname.includes('railway.app')) {
                return `${protocol}//${hostname}/realtime`;
            }
            
            // Render deployments
            if (hostname.includes('onrender.com')) {
                return `${protocol}//${hostname}/realtime`;
            }
            
            // Local development
            return 'ws://localhost:3001/realtime';
        };
        
        const PROXY_URL = getProxyURL();
        const REALTIME_MODEL = 'gpt-4o-realtime-preview-2024-10-01';
        
        console.log('🔧 Environment detection:');
        console.log('   Hostname:', window.location.hostname);
        console.log('   Protocol:', window.location.protocol);
        console.log('   Full URL:', window.location.href);
        console.log('🔧 Using proxy URL:', PROXY_URL);
        
        // Professional OpenAI Realtime API Configuration
        const REALTIME_CONFIG = {
            SAMPLE_RATE: 24000,           // Required 24kHz sample rate
            CHUNK_SIZE: 1200,             // ~50ms chunks (24000 * 0.05)
            BUFFER_SIZE: 4096,            // Audio processing buffer
            PCM_SCALE: 32767,             // 16-bit PCM scaling
            MIN_AMPLITUDE: 300,           // Noise gate threshold
            SESSION_READY_DELAY: 1000,    // Wait before sending audio
        };
        
        // State variables - Enterprise Grade
        let realtimeSocket = null;
        let audioStream = null;
        let audioContext = null;
        let audioProcessor = null;
        let audioBuffer = [];
        let isConnected = false;
        let isSessionReady = false;
        let isActivated = false;
        let isSpeaking = false;
        let sessionStartTime = 0;
        let lastAudioSendTime = 0;
        let connectionAttempts = 0;
        let maxRetries = 5;

        // Professional Audio Initialization - Industry Standard
        async function initializeAudio() {
            try {
                console.log('🎤 Initializing professional audio system...');
                
                // Create AudioContext with exact OpenAI requirements
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: REALTIME_CONFIG.SAMPLE_RATE,
                    latencyHint: 'interactive'
                });
                
                console.log(`🔧 Audio Context: ${audioContext.sampleRate}Hz, state: ${audioContext.state}`);
                
                // Request high-quality audio stream with exact specifications
                audioStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: REALTIME_CONFIG.SAMPLE_RATE,
                        channelCount: 1,                    // Mono as required
                        echoCancellation: true,             // Essential for voice
                        noiseSuppression: true,             // Reduce background noise
                        autoGainControl: true,              // Consistent volume
                        googEchoCancellation: true,         // Chrome-specific
                        googNoiseSuppression: true,         // Chrome-specific
                        googAutoGainControl: true,          // Chrome-specific
                        googHighpassFilter: true,           // Remove low-frequency noise
                        mozEchoCancellation: true,          // Firefox-specific
                        mozNoiseSuppression: true,          // Firefox-specific
                        mozAutoGainControl: true            // Firefox-specific
                    } 
                });
                
                console.log('✅ Professional audio system initialized');
                console.log(`📊 Stream settings: ${audioStream.getAudioTracks()[0].getSettings().sampleRate}Hz`);
                return true;
                
            } catch (error) {
                console.error('❌ Professional audio initialization failed:', error);
                setPersonaState('idle', 'Microphone access required');
                return false;
            }
        }

        // Connect to OpenAI Realtime API through proxy
        async function connectToRealtimeAPI() {
            try {
                console.log('🔄 Connecting to OpenAI Realtime API...');
                setPersonaState('idle', 'CONNECTING...');
                
                const wsUrl = `${PROXY_URL}?model=${REALTIME_MODEL}`;
                realtimeSocket = new WebSocket(wsUrl);
                
                // Override close method to track what's calling it
                const originalClose = realtimeSocket.close.bind(realtimeSocket);
                realtimeSocket.close = function(code, reason) {
                    console.error('⚠️ WebSocket.close() called!');
                    console.error('⚠️ Call stack:', new Error().stack);
                    console.error('⚠️ Code:', code, 'Reason:', reason);
                    if (!preventClose) {
                        return originalClose(code, reason);
                    } else {
                        console.log('🛡️ Close prevented by preventClose flag');
                    }
                };
                
                realtimeSocket.onopen = () => {
                    console.log('✅ Connected to Realtime API proxy');
                    console.log('🔧 Keeping connection alive, waiting for session.created...');
                    
                    setPersonaState('idle', 'Connected, waiting for session...');
                    isConnected = true;
                    preventClose = true; // Prevent accidental closure

                    // Show mode indicator
                    modeIndicator.classList.add('visible');
                    setTimeout(() => {
                        modeIndicator.classList.remove('visible');
                    }, 3000);
                    
                    // Keep connection alive - send a ping if needed
                    const keepAlive = setInterval(() => {
                        if (realtimeSocket && realtimeSocket.readyState === WebSocket.OPEN && !isSessionReady) {
                            console.log('🔄 Keeping connection alive, still waiting for session...');
                        } else {
                            clearInterval(keepAlive);
                        }
                    }, 2000);
                    
                    // Add timeout to detect if session.created never arrives
                    setTimeout(() => {
                        if (!isSessionReady) {
                            console.warn('⚠️ No session.created received after 15 seconds');
                            console.log('🔧 Server logs show session.created sent, but client not receiving');
                            setPersonaState('idle', 'Session timeout - message forwarding issue');
                        }
                        clearInterval(keepAlive);
                    }, 15000);
                };
                
                realtimeSocket.onmessage = handleRealtimeMessage;
                
                realtimeSocket.onerror = (error) => {
                    console.error('❌ Realtime WebSocket error:', error);
                    console.error('❌ Attempted URL:', PROXY_URL);
                    
                    // Provide specific error messages based on URL
                    if (PROXY_URL.includes('vercel.app') || PROXY_URL.includes('railway.app') || PROXY_URL.includes('onrender.com')) {
                        setPersonaState('idle', 'Server deployment needed');
                    } else if (PROXY_URL.includes('app.github.dev')) {
                        setPersonaState('idle', 'Codespace server offline');
                    } else if (PROXY_URL.includes('localhost')) {
                        setPersonaState('idle', 'Local server not running');
                    } else {
                        setPersonaState('idle', 'Connection failed');
                    }
                };
                
                realtimeSocket.onclose = (event) => {
                    console.log('🔌 Realtime WebSocket closed:', event.code, event.reason);
                    console.log('🔌 Connection URL was:', PROXY_URL);
                    console.log('🔌 isSessionReady was:', isSessionReady);
                    console.log('🔌 Close triggered by:', new Error().stack);
                    
                    // Provide helpful error messages based on close code and URL
                    if (event.code === 1001) {
                        console.error('❌ Client initiated close - investigating cause');
                        setPersonaState('idle', 'Connection terminated unexpectedly');
                    } else if (event.code === 1006) {
                        setPersonaState('idle', 'Server unreachable');
                    } else if (event.code === 1000) {
                        setPersonaState('idle', 'Connection closed');
                    } else {
                        setPersonaState('idle', 'Disconnected');
                    }
                    
                    isConnected = false;
                };
                
            } catch (error) {
                console.error('❌ Failed to connect to Realtime API:', error);
                setPersonaState('idle', 'Connection error');
            }
        }

        // Send a test audio buffer to validate the connection
        function sendTestAudioBuffer() {
            if (!isConnected || !isSessionReady || !realtimeSocket || realtimeSocket.readyState !== WebSocket.OPEN) {
                console.log('⚠️ Not ready for test audio');
                return;
            }
            
            console.log('🧪 Sending test audio buffer...');
            
            // Create a simple sine wave test audio (440Hz tone for 100ms)
            const sampleRate = 24000;
            const duration = 0.1; // 100ms
            const frequency = 440; // A4 note
            const samples = Math.floor(sampleRate * duration);
            
            const testAudio = new Int16Array(samples);
            for (let i = 0; i < samples; i++) {
                const t = i / sampleRate;
                const amplitude = 0.1 * Math.sin(2 * Math.PI * frequency * t); // Low volume
                testAudio[i] = Math.round(amplitude * 32767);
            }
            
            const testMessage = JSON.stringify({
                type: 'input_audio_buffer.append',
                audio: arrayBufferToBase64(testAudio.buffer)
            });
            
            console.log('🧪 Test audio:', {
                samples: testAudio.length,
                bufferSize: testAudio.buffer.byteLength,
                maxAmplitude: Math.max(...testAudio.map(Math.abs))
            });
            
            realtimeSocket.send(testMessage);
        }

        // Industry-Standard Real-time Audio Processing
        function startRealtimeAudio() {
            if (!isConnected || !isSessionReady || !audioStream || !audioContext) {
                console.log('⚠️ Audio system not ready:', { 
                    isConnected, 
                    isSessionReady, 
                    hasAudioStream: !!audioStream,
                    hasAudioContext: !!audioContext 
                });
                return;
            }
            
            console.log('🎤 Starting professional real-time audio processing...');
            console.log(`🔧 Target: ${REALTIME_CONFIG.CHUNK_SIZE} samples (~50ms chunks)`);
            
            try {
                // Create high-quality audio processing chain
                const source = audioContext.createMediaStreamSource(audioStream);
                
                // Use optimal buffer size for real-time processing
                audioProcessor = audioContext.createScriptProcessor(
                    REALTIME_CONFIG.BUFFER_SIZE, 1, 1
                );
                
                audioProcessor.onaudioprocess = handleAudioProcess;
                
                // Connect audio processing chain
                source.connect(audioProcessor);
                audioProcessor.connect(audioContext.destination);
                
                console.log('✅ Professional audio processing chain established');
                console.log(`📊 Buffer size: ${REALTIME_CONFIG.BUFFER_SIZE}, Chunk target: ${REALTIME_CONFIG.CHUNK_SIZE}`);
                
            } catch (error) {
                console.error('❌ Failed to start audio processing:', error);
                setPersonaState('idle', 'Audio processing failed');
            }
        }
        
        // Professional Audio Processing Handler - Industry Standard
        function handleAudioProcess(event) {
            // Wait for session to be fully ready
            if (!isConnected || !isSessionReady || 
                Date.now() - sessionStartTime < REALTIME_CONFIG.SESSION_READY_DELAY) {
                return;
            }
            
            try {
                const inputData = event.inputBuffer.getChannelData(0);
                
                // Validate audio data integrity
                if (!inputData || inputData.length !== REALTIME_CONFIG.BUFFER_SIZE) {
                    return;
                }
                
                // Add to buffer for optimal chunk processing
                audioBuffer.push(...inputData);
                
                // Process when we have optimal chunk size (~50ms)
                while (audioBuffer.length >= REALTIME_CONFIG.CHUNK_SIZE) {
                    const chunk = audioBuffer.splice(0, REALTIME_CONFIG.CHUNK_SIZE);
                    processAudioChunk(chunk);
                }
                
            } catch (error) {
                console.error('❌ Audio processing error:', error);
            }
        }
        
        // Process Audio Chunks - Optimized for OpenAI Realtime API
        function processAudioChunk(audioChunk) {
            try {
                // Convert to high-quality PCM16 format
                const pcm16Data = new Int16Array(audioChunk.length);
                let maxAmplitude = 0;
                let signalStrength = 0;
                
                for (let i = 0; i < audioChunk.length; i++) {
                    // Professional-grade sample validation
                    if (!isFinite(audioChunk[i]) || isNaN(audioChunk[i])) {
                        console.warn('⚠️ Invalid audio sample detected, skipping chunk');
                        return;
                    }
                    
                    // High-quality PCM16 conversion with proper scaling
                    const sample = Math.max(-REALTIME_CONFIG.PCM_SCALE, 
                        Math.min(REALTIME_CONFIG.PCM_SCALE, 
                            Math.round(audioChunk[i] * REALTIME_CONFIG.PCM_SCALE)));
                    
                    pcm16Data[i] = sample;
                    const amplitude = Math.abs(sample);
                    maxAmplitude = Math.max(maxAmplitude, amplitude);
                    signalStrength += amplitude;
                }
                
                // Professional noise gate - only process meaningful audio
                const avgAmplitude = signalStrength / audioChunk.length;
                if (maxAmplitude < REALTIME_CONFIG.MIN_AMPLITUDE || avgAmplitude < 50) {
                    return; // Skip low-quality audio
                }
                
                // Rate limiting for optimal performance
                const now = Date.now();
                if (now - lastAudioSendTime < 45) { // ~22fps max
                    return;
                }
                lastAudioSendTime = now;
                
                // Send high-quality audio to OpenAI
                sendAudioToRealtime(pcm16Data);
                
                // Professional monitoring (1% sampling)
                if (Math.random() < 0.01) {
                    console.log('📊 Audio Quality:', {
                        samples: pcm16Data.length,
                        maxAmplitude: maxAmplitude,
                        avgAmplitude: Math.round(avgAmplitude),
                        quality: maxAmplitude > 1000 ? 'High' : 'Medium',
                        timeSinceSession: now - sessionStartTime
                    });
                }
                
            } catch (error) {
                console.error('❌ Audio chunk processing error:', error);
            }
        }
        
        // Send Audio to OpenAI Realtime API - Optimized
        function sendAudioToRealtime(pcm16Data) {
            if (!realtimeSocket || realtimeSocket.readyState !== WebSocket.OPEN) {
                return;
            }
            
            try {
                const audioMessage = JSON.stringify({
                    type: 'input_audio_buffer.append',
                    audio: arrayBufferToBase64(pcm16Data.buffer)
                });
                
                realtimeSocket.send(audioMessage);
                
            } catch (error) {
                console.error('❌ Failed to send audio to Realtime API:', error);
            }
        }

        // Professional Audio Response Playback
        let audioResponseQueue = [];
        let isPlayingResponse = false;
        
        async function processAudioResponseQueue() {
            if (audioResponseQueue.length === 0) {
                isPlayingResponse = false;
                return;
            }
            
            isPlayingResponse = true;
            const base64Audio = audioResponseQueue.shift();
            
            try {
                // Decode high-quality PCM16 audio from OpenAI
                const audioData = base64ToArrayBuffer(base64Audio);
                const pcmData = new Int16Array(audioData);
                
                // Create professional audio buffer
                const audioBuffer = audioContext.createBuffer(
                    1, pcmData.length, REALTIME_CONFIG.SAMPLE_RATE
                );
                const channelData = audioBuffer.getChannelData(0);
                
                // High-quality PCM16 to float32 conversion
                for (let i = 0; i < pcmData.length; i++) {
                    channelData[i] = pcmData[i] / REALTIME_CONFIG.PCM_SCALE;
                }
                
                // Create and play audio with optimal settings
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                
                source.onended = () => {
                    processAudioResponseQueue();
                };
                
                source.start();
                
            } catch (error) {
                console.error('❌ Audio response playback error:', error);
                processAudioResponseQueue(); // Continue with next chunk
            }
        }

        // Handle Realtime API messages
        function handleRealtimeMessage(event) {
            // Handle both text and binary messages
            let message;
            try {
                if (typeof event.data === 'string') {
                    message = JSON.parse(event.data);
                    console.log('📨 Received text message:', message.type, message);
                    
                    // Special handling for session.created
                    if (message.type === 'session.created') {
                        console.log('🎯 FOUND session.created message!');
                        console.log('🎯 Message content:', JSON.stringify(message, null, 2));
                    }
                } else if (event.data instanceof Blob) {
                    // Binary data (audio) - try to read as text first in case it's JSON
                    console.log('📦 Received binary data (Blob):', event.data.size, 'bytes');
                    
                    // Try to read Blob as text in case it's actually JSON
                    const reader = new FileReader();
                    reader.onload = function(e) {
                        try {
                            const textData = e.target.result;
                            if (textData.trim().startsWith('{')) {
                                console.log('🔍 Blob contains JSON text:', textData);
                                const jsonMessage = JSON.parse(textData);
                                if (jsonMessage.type === 'session.created') {
                                    console.log('🎯 FOUND session.created in BLOB!');
                                    // Process it as if it was a text message
                                    handleRealtimeMessage({data: textData});
                                }
                            }
                        } catch (e) {
                            console.log('📦 Blob is binary audio data');
                        }
                    };
                    reader.readAsText(event.data);
                    return; // Skip binary messages for now
                } else {
                    // Other binary data
                    console.log('📦 Received binary data (other):', event.data);
                    return; // Skip binary messages for now
                }
            } catch (error) {
                console.error('❌ Failed to parse WebSocket message:', error);
                console.error('❌ Event data type:', typeof event.data);
                console.error('❌ Event data:', event.data);
                return;
            }
            
            console.log('📨 Realtime message:', message.type);

            switch (message.type) {
                case 'session.created':
                    console.log('✅ Realtime session created - CLIENT RECEIVED!');
                    console.log('🎯 Session details:', message.session);
                    connectionAttempts = 0; // Reset retry counter on success
                    sessionStartTime = Date.now(); // Track session start time
                    
                    // CRITICAL TEST: Don't send ANY session.update - use pure defaults
                    console.log('🔧 Using OpenAI defaults: PCM16 audio, alloy voice, server VAD');
                    isSessionReady = true;
                    setPersonaState('idle', 'Ready! Speak now');
                    
                    // Start professional audio processing after session stabilizes
                    setTimeout(() => {
                        if (isSessionReady && isConnected) {
                            startRealtimeAudio();
                        }
                    }, REALTIME_CONFIG.SESSION_READY_DELAY);
                    break;
                
                case 'session.updated':
                    console.log('✅ Session updated (not expected in this test)');
                    break;
                
                case 'input_audio_buffer.speech_started':
                    console.log('🎤 Speech started - VAD detected audio');
                    setPersonaState('listening', 'Listening...');
                    break;
                
                case 'input_audio_buffer.speech_stopped':
                    console.log('🎤 Speech stopped - processing speech');
                    setPersonaState('thinking', 'Processing...');
                    break;
                
                case 'response.audio.delta':
                    if (message.delta) {
                        // Professional audio response handling
                        if (!isSpeaking) {
                            setPersonaState('speaking', 'Speaking...');
                            isSpeaking = true;
                        }
                        
                        audioResponseQueue.push(message.delta);
                        if (!isPlayingResponse) {
                            processAudioResponseQueue();
                        }
                    }
                    break;
                
                case 'response.audio.done':
                    console.log('🔊 Audio response complete');
                    setPersonaState('idle', 'Ready');
                    isSpeaking = false;
                    break;
                
                case 'response.done':
                    console.log('✅ Response complete');
                    setPersonaState('idle', 'Ready');
                    break;
                
                case 'error':
                    console.error('❌ OpenAI Realtime API Error:', message.error);
                    
                    // Professional error handling with intelligent retry
                    if (message.error?.type === 'server_error' && connectionAttempts < maxRetries) {
                        connectionAttempts++;
                        const delay = Math.min(2000 * connectionAttempts, 15000); // Progressive delay
                        
                        console.log(`🔄 Server error detected - retrying (${connectionAttempts}/${maxRetries}) in ${delay/1000}s...`);
                        console.log(`📋 Error details: ${message.error.message}`);
                        
                        setPersonaState('idle', `Reconnecting... (${connectionAttempts}/${maxRetries})`);
                        
                        setTimeout(() => {
                            if (realtimeSocket) {
                                realtimeSocket.close();
                            }
                            // Clean reset before retry
                            isSessionReady = false;
                            isConnected = false;
                            audioBuffer = [];
                            connectToRealtimeAPI();
                        }, delay);
                        
                    } else {
                        // Max retries reached - professional error display
                        console.error('❌ Maximum retry attempts reached');
                        console.log('📋 Session ID for support:', message.error?.event_id || 'N/A');
                        
                        setPersonaState('idle', 'Service temporarily unavailable');
                        connectionAttempts = 0;
                        
                        // Allow manual retry after cooldown
                        setTimeout(() => {
                            isActivated = false;
                            setPersonaState('idle', 'TAP TO RETRY');
                            touchIndicator.style.display = 'block';
                            touchIndicator.textContent = 'TAP TO RETRY';
                            touchIndicator.classList.add('pulse-hint');
                        }, 5000);
                    }
                    break;
            }
        }


        // Utility functions
        function arrayBufferToBase64(buffer) {
            const bytes = new Uint8Array(buffer);
            let binary = '';
            for (let i = 0; i < bytes.byteLength; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return btoa(binary);
        }
        
        // μ-law encoding (OpenAI default format)
        function linearToUlaw(pcm) {
            const BIAS = 0x84;
            const CLIP = 32635;
            
            let sign = (pcm >> 8) & 0x80;
            if (sign) pcm = -pcm;
            if (pcm > CLIP) pcm = CLIP;
            pcm += BIAS;
            
            let exponent = 7;
            let exponentMask = 0x4000;
            for (let i = 0; i < 8; i++) {
                if ((pcm & exponentMask) !== 0) break;
                exponent--;
                exponentMask >>= 1;
            }
            
            const mantissa = (pcm >> (exponent + 3)) & 0x0F;
            const ulaw = ~(sign | (exponent << 4) | mantissa);
            
            return ulaw & 0xFF;
        }
        
        // μ-law decoding (OpenAI default format)
        function ulawToLinear(ulaw) {
            const BIAS = 0x84;
            
            ulaw = ~ulaw;
            const sign = ulaw & 0x80;
            const exponent = (ulaw >> 4) & 0x07;
            const mantissa = ulaw & 0x0F;
            
            let sample = (mantissa << (exponent + 3)) + BIAS;
            if (exponent > 0) sample += (1 << (exponent + 2));
            
            return sign ? -sample : sample;
        }
        
        function base64ToArrayBuffer(base64) {
            const binaryString = atob(base64);
            const bytes = new Uint8Array(binaryString.length);
            for (let i = 0; i < binaryString.length; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        // Visual state management
        function setPersonaState(state, text) {
            personaOrb.className = 'orb';
            personaOrb.classList.add(state);
            statusText.textContent = text ? text.toUpperCase() : '';
            
            if (state !== 'idle' || text !== 'CONNECTING...') {
                touchIndicator.style.display = 'none';
            }
        }


        // Professional Voice Assistant Activation
        async function activateAssistant() {
            if (!isActivated) {
                isActivated = true;
                touchIndicator.textContent = 'ACTIVATING...';
                touchIndicator.classList.remove('pulse-hint');
                
                setPersonaState('idle', 'INITIALIZING PROFESSIONAL VOICE AI...');
                
                console.log('🎯 Initializing Industry-Grade OpenAI Realtime Voice Assistant');
                
                // Initialize professional audio system
                const audioInitialized = await initializeAudio();
                if (!audioInitialized) {
                    setPersonaState('idle', 'Microphone access required');
                    isActivated = false;
                    setTimeout(() => {
                        touchIndicator.style.display = 'block';
                        touchIndicator.textContent = 'TAP TO RETRY';
                        touchIndicator.classList.add('pulse-hint');
                    }, 3000);
                    return;
                }
                
                // Connect to OpenAI Realtime API
                await connectToRealtimeAPI();
                
                // Hide activation indicator
                setTimeout(() => {
                    touchIndicator.style.display = 'none';
                }, 2000);
            }
        }
        
        
        // Codespace configuration helpers
        function showCodespaceConfig() {
            document.getElementById('codespace-config').style.display = 'block';
        }
        
        function hideCodespaceConfig() {
            document.getElementById('codespace-config').style.display = 'none';
        }
        
        function saveCodespaceUrl() {
            const input = document.getElementById('codespace-input');
            const url = input.value.trim();
            
            if (url && url.includes('app.github.dev')) {
                const wsUrl = url.replace('https:', 'wss:') + '/realtime';
                localStorage.setItem('user_provided_codespace', wsUrl);
                localStorage.setItem('codespace_url', wsUrl);
                hideCodespaceConfig();
                
                // Restart the connection with new URL
                if (realtimeSocket) {
                    realtimeSocket.close();
                }
                
                setTimeout(() => {
                    connectToRealtimeAPI();
                }, 1000);
                
                console.log('✅ Saved codespace URL:', wsUrl);
            } else {
                alert('⚠️ Please enter a valid Codespace URL (format: https://name-3001.app.github.dev)');
            }
        }

        // Event listeners
        document.body.addEventListener('click', activateAssistant, { once: true });
        document.body.addEventListener('touchstart', activateAssistant, { once: true });
        personaOrb.addEventListener('click', activateAssistant);
        personaOrb.addEventListener('touchstart', activateAssistant);

    </script>
</body>
</html>